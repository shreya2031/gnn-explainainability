{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T20:14:50.377368Z",
     "start_time": "2024-03-13T20:14:50.318273Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from inferred_stypes import dataset2inferred_stypes\n",
    "from model import Model\n",
    "from text_embedder import GloveTextEmbedding\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.seed import seed_everything\n",
    "from tqdm import tqdm\n",
    "\n",
    "from relbench.data import NodeTask, RelBenchDataset\n",
    "from relbench.data.task_base import TaskType\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.external.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "import dgl\n",
    "\n",
    "from dgl.nn import HeteroGNNExplainer\n",
    "from torch_geometric.data import HeteroData\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"rel-stackex\")\n",
    "parser.add_argument(\"--task\", type=str, default=\"rel-stackex-engage\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01)\n",
    "parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "parser.add_argument(\"--channels\", type=int, default=128)\n",
    "parser.add_argument(\"--aggr\", type=str, default=\"sum\")\n",
    "parser.add_argument(\"--num_layers\", type=int, default=2)\n",
    "parser.add_argument(\"--num_neighbors\", type=int, default=128)\n",
    "parser.add_argument(\"--temporal_strategy\", type=str, default=\"uniform\")\n",
    "parser.add_argument(\"--num_workers\", type=int, default=1)\n",
    "args = parser.parse_args(\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T20:24:03.829789Z",
     "start_time": "2024-03-13T20:24:03.787935Z"
    }
   },
   "id": "ff564a954c29b1a2",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making Database object from raw files...\n",
      "done in 60.87 seconds.\n",
      "reindexing pkeys and fkeys...\n",
      "done in 4.43 seconds.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(42)\n",
    "\n",
    "root_dir = \"./data\"\n",
    "\n",
    "# TODO: remove process=True once correct data/task is uploaded.\n",
    "dataset: RelBenchDataset = get_dataset(name=args.dataset, process=True)\n",
    "task: NodeTask = dataset.get_task(args.task, process=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T20:16:35.572881Z",
     "start_time": "2024-03-13T20:15:04.408396Z"
    }
   },
   "id": "7dca5bf470394092",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m col_to_stype_dict \u001B[38;5;241m=\u001B[39m dataset2inferred_stypes[args\u001B[38;5;241m.\u001B[39mdataset]\n\u001B[1;32m----> 3\u001B[0m data, col_stats_dict \u001B[38;5;241m=\u001B[39m \u001B[43mmake_pkey_fkey_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcol_to_stype_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcol_to_stype_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext_embedder_cfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTextEmbedderConfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtext_embedder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mGloveTextEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_materialized_cache\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# print(\"data:\",data['comments']['tf'])\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#print(\"data:\\n\",data)\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\relbench\\external\\graph.py:106\u001B[0m, in \u001B[0;36mmake_pkey_fkey_graph\u001B[1;34m(db, col_to_stype_dict, text_embedder_cfg, cache_dir)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;66;03m# Add time attribute:\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m table\u001B[38;5;241m.\u001B[39mtime_col \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    105\u001B[0m     data[table_name]\u001B[38;5;241m.\u001B[39mtime \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(\n\u001B[1;32m--> 106\u001B[0m         \u001B[43mto_unix_time\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_col\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m     )\n\u001B[0;32m    109\u001B[0m \u001B[38;5;66;03m# Add edges:\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m fkey_name, pkey_table_name \u001B[38;5;129;01min\u001B[39;00m table\u001B[38;5;241m.\u001B[39mfkey_col_to_pkey_table\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\relbench\\external\\utils.py:9\u001B[0m, in \u001B[0;36mto_unix_time\u001B[1;34m(ser)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Converts a :class:`pandas.Timestamp` series to UNIX timestamp\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m(in seconds).\"\"\"\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m ser\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01min\u001B[39;00m [np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime64[s]\u001B[39m\u001B[38;5;124m\"\u001B[39m), np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime64[ns]\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m----> 9\u001B[0m unix_time \u001B[38;5;241m=\u001B[39m \u001B[43mser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ser\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime64[ns]\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     11\u001B[0m     unix_time \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m9\u001B[39m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\generic.py:6640\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6634\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6635\u001B[0m         ser\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors) \u001B[38;5;28;01mfor\u001B[39;00m _, ser \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   6636\u001B[0m     ]\n\u001B[0;32m   6638\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6639\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6640\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6641\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(new_data, axes\u001B[38;5;241m=\u001B[39mnew_data\u001B[38;5;241m.\u001B[39maxes)\n\u001B[0;32m   6642\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    428\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 430\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    361\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 363\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    364\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    366\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001B[0m\n\u001B[0;32m    755\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan not squeeze with more than one column.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    756\u001B[0m     values \u001B[38;5;241m=\u001B[39m values[\u001B[38;5;241m0\u001B[39m, :]  \u001B[38;5;66;03m# type: ignore[call-overload]\u001B[39;00m\n\u001B[1;32m--> 758\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    760\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    762\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    234\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 237\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(values, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;66;03m# i.e. ExtensionArray\u001B[39;00m\n\u001B[1;32m--> 179\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    182\u001B[0m     values \u001B[38;5;241m=\u001B[39m _astype_nansafe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:739\u001B[0m, in \u001B[0;36mDatetimeArray.astype\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    737\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, PeriodDtype):\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_period(freq\u001B[38;5;241m=\u001B[39mdtype\u001B[38;5;241m.\u001B[39mfreq)\n\u001B[1;32m--> 739\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDatetimeLikeArrayMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:480\u001B[0m, in \u001B[0;36mDatetimeLikeArrayMixin.astype\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    478\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masi8\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mint64:\n\u001B[1;32m--> 480\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not supported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDo obj.astype(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m).astype(dtype) instead\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    483\u001B[0m     )\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m    486\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[1;31mTypeError\u001B[0m: Converting from datetime64[ns] to int32 is not supported. Do obj.astype('int64').astype(dtype) instead"
     ]
    }
   ],
   "source": [
    "col_to_stype_dict = dataset2inferred_stypes[args.dataset]\n",
    "\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    dataset.db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=TextEmbedderConfig(\n",
    "        text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    "    ),\n",
    "    cache_dir=os.path.join(root_dir, f\"{args.dataset}_materialized_cache\"),\n",
    ")\n",
    "# print(\"data:\",data['comments']['tf'])\n",
    "#print(\"data:\\n\",data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T20:23:10.951727Z",
     "start_time": "2024-03-13T20:23:00.666992Z"
    }
   },
   "id": "266a00d515abaf48",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loader_dict: Dict[str, NeighborLoader] = {}\n",
    "for split, table in [\n",
    "    (\"train\", task.train_table),\n",
    "    (\"val\", task.val_table),\n",
    "    (\"test\", task.test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(table=table, task=task)\n",
    "    entity_table = table_input.nodes[0]\n",
    "    loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[\n",
    "            int(args.num_neighbors / 2**i) for i in range(args.num_layers)\n",
    "        ],\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        batch_size=args.batch_size,\n",
    "        temporal_strategy=args.temporal_strategy,\n",
    "        shuffle=split == \"train\",\n",
    "        num_workers=args.num_workers,\n",
    "        persistent_workers=args.num_workers > 0,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "846d440b0f2977a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "edge_index_dict = {}\n",
    "for edge_type in data.edge_types:\n",
    "    edge_index_dict[edge_type] = data[edge_type].edge_index\n",
    "\n",
    "#print(\"edge types:\\n\",data.edge_types)\n",
    "\n",
    "x_dict = {}\n",
    "for node_type in data.node_types:\n",
    "    # Assuming data[node_type].tf.to_tensor() is the method to convert TensorFrame to a tensor.\n",
    "    # Adjust this method based on the actual implementation of TensorFrame.\n",
    "    x_dict[node_type] = data[node_type].tf.to_tensor() if hasattr(data[node_type].tf, 'to_tensor') else data[node_type].tf\n",
    "#print(x_dict)\n",
    "#print(\"node types:\\n\",data.node_types)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Your code that creates and starts processes should go here\n",
    "#     # This ensures that multiprocessing is handled correctly\n",
    "#     for batch in loader_dict[\"train\"]:\n",
    "#         batch = batch.to(device)\n",
    "#         print(\"batch:\\n\", batch)\n",
    "\n",
    "\n",
    "#print(\"task.train_table\\n\",task.train_table)\n",
    "#print(\"task.entity_table\\n\",task.entity_table)\n",
    "\n",
    "# print(\"table_input:\",table_input)\n",
    "# print(\"table_input.nodes:\",table_input.nodes)\n",
    "# print(\"table_input.nodes[0]:\",table_input.nodes[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "529c571e32743aed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# homogeneous_data = data.to_homogeneous()\n",
    "# print(\"homogeneous_data:\\n\",homogeneous_data)\n",
    "\n",
    "graph_data = {}\n",
    "\n",
    "# For each edge type in the HeteroData\n",
    "for (src_type, edge_type, dst_type), edge_data in data.edge_index_dict.items():\n",
    "    src_nodes, dst_nodes = edge_data\n",
    "    # Convert PyG edge index format to DGL format\n",
    "    graph_data[(src_type, edge_type, dst_type)] = (src_nodes.numpy(), dst_nodes.numpy())\n",
    "\n",
    "# Create the DGL heterograph\n",
    "dgl_graph = dgl.heterograph(graph_data)\n",
    "print(\"dgl_graph:\\n\",dgl_graph)\n",
    "print(\"dgl_graph.nodes['users']:\\n\",dgl_graph.nodes['users'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76bd69eca5f1b31b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "for node_type in data.node_types:\n",
    "    tensor_frame = data[node_type]['tf']\n",
    "\n",
    "    # Hypothetical method to extract data. Replace with actual method to access TensorFrame data.\n",
    "    raw_data = tensor_frame.get_data()  # Assume this returns a dict with 'timestamp' and 'embedding'\n",
    "\n",
    "    # Convert each part of the data to a PyTorch tensor. You may need to handle data types appropriately.\n",
    "    for key, value in raw_data.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            tensor_data = torch.from_numpy(value)\n",
    "        elif isinstance(value, list):\n",
    "            tensor_data = torch.tensor(value)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported data type for {key} in TensorFrame.\")\n",
    "\n",
    "        # Assuming you want to concatenate all features into a single tensor for each node\n",
    "        # You might need to adjust this based on how your model expects the features\n",
    "        if 'features' not in dgl_graph.nodes[node_type].data:\n",
    "            dgl_graph.nodes[node_type].data['features'] = tensor_data\n",
    "        else:\n",
    "            dgl_graph.nodes[node_type].data['features'] = torch.cat(\n",
    "                (dgl_graph.nodes[node_type].data['features'], tensor_data), dim=1)\n",
    "\n",
    "# # Add node features for each node type from HeteroData to DGL graph\n",
    "# for node_type in data.node_types:\n",
    "#     # Assuming a direct conversion of TensorFrame to tensor, adjust as needed\n",
    "#     #dgl_graph.nodes[node_type].data['h'] = data[node_type]['tf'].to_tensor()\n",
    "#     print(\"data[node_type]['tf']:\\n\",data[node_type]['tf'])\n",
    "#     dgl_graph.nodes[node_type].data['h'] = data[node_type]['tf']\n",
    "#\n",
    "#\n",
    "#\n",
    "# feat = {ntype: dgl_graph.nodes[ntype].data['h'] for ntype in dgl_graph.ntypes}\n",
    "#\n",
    "# print(\"feat:\\n\",feat)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7bdbbb15daf9ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# explainer = Explainer(\n",
    "#     model,  # It is assumed that model outputs a single tensor.\n",
    "#     algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "#     explanation_type='model',\n",
    "#     node_mask_type='attributes',\n",
    "#     edge_mask_type='object',\n",
    "#     model_config = dict(\n",
    "#         mode='binary_classification',\n",
    "#         task_level=\"node\",\n",
    "#         return_type='probs',  # Model returns probabilities.\n",
    "#     ),\n",
    "# )\n",
    "#\n",
    "# hetero_explanation = explainer(\n",
    "#     x_dict,\n",
    "#     edge_index_dict,\n",
    "#     index=torch.tensor([1, 3]),\n",
    "#  )\n",
    "# print(hetero_explanation.edge_mask_dict)\n",
    "# print(hetero_explanation.node_mask_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c39365a88578d5f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59b2341cb8ab7c0f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load(\"C:\\\\Users\\\\Shreya Reddy\\\\Downloads\\\\relbenchmain\\\\examples\\\\saved_model.pth\",\n",
    "                   map_location=torch.device('cpu'))\n",
    "explainer = HeteroGNNExplainer(model, num_hops=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa9edd751b43f94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feat_mask, edge_mask = explainer.explain_graph(dgl_graph, feat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6ceb16b9900d7e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "460796423710947e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb50fa3349a6c84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9b4bfe21f9be002"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc9272c3432c48d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fd2e74c40c34b815"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
