{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:41:49.415496Z",
     "start_time": "2024-03-14T09:41:39.920986Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from inferred_stypes import dataset2inferred_stypes\n",
    "from model import Model\n",
    "from text_embedder import GloveTextEmbedding\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.seed import seed_everything\n",
    "from tqdm import tqdm\n",
    "\n",
    "from relbench.data import NodeTask, RelBenchDataset\n",
    "from relbench.data.task_base import TaskType\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.external.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "import dgl\n",
    "\n",
    "from dgl.nn import HeteroGNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"rel-stackex\")\n",
    "parser.add_argument(\"--task\", type=str, default=\"rel-stackex-engage\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01)\n",
    "parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "parser.add_argument(\"--channels\", type=int, default=128)\n",
    "parser.add_argument(\"--aggr\", type=str, default=\"sum\")\n",
    "parser.add_argument(\"--num_layers\", type=int, default=2)\n",
    "parser.add_argument(\"--num_neighbors\", type=int, default=128)\n",
    "parser.add_argument(\"--temporal_strategy\", type=str, default=\"uniform\")\n",
    "parser.add_argument(\"--num_workers\", type=int, default=1)\n",
    "args = parser.parse_args(\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:41:50.802623Z",
     "start_time": "2024-03-14T09:41:50.778014Z"
    }
   },
   "id": "b262ef50864f26d7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making Database object from raw files...\n",
      "done in 33.54 seconds.\n",
      "reindexing pkeys and fkeys...\n",
      "done in 2.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(42)\n",
    "\n",
    "root_dir = \"./data\"\n",
    "\n",
    "# TODO: remove process=True once correct data/task is uploaded.\n",
    "dataset: RelBenchDataset = get_dataset(name=args.dataset, process=True)\n",
    "task: NodeTask = dataset.get_task(args.task, process=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:42:29.179112Z",
     "start_time": "2024-03-14T09:41:52.512131Z"
    }
   },
   "id": "9a05fb04d08234bb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Database()"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.db"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:14:57.630788Z",
     "start_time": "2024-03-14T09:14:57.625280Z"
    }
   },
   "id": "80805baad406c161",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "col_to_stype_dict = dataset2inferred_stypes[args.dataset]\n",
    "\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    dataset.db,\n",
    "    col_to_stype_dict=col_to_stype_dict,\n",
    "    text_embedder_cfg=TextEmbedderConfig(\n",
    "        text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    "    ),\n",
    "    cache_dir=os.path.join(root_dir, f\"{args.dataset}_materialized_cache\"),\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:42:59.538237Z",
     "start_time": "2024-03-14T09:42:34.383152Z"
    }
   },
   "id": "33b1aa5e75e12cc7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loader_dict: Dict[str, NeighborLoader] = {}\n",
    "for split, table in [\n",
    "    (\"train\", task.train_table),\n",
    "    (\"val\", task.val_table),\n",
    "    (\"test\", task.test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(table=table, task=task)\n",
    "    entity_table = table_input.nodes[0]\n",
    "    loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[\n",
    "            int(args.num_neighbors / 2**i) for i in range(args.num_layers)\n",
    "        ],\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        batch_size=args.batch_size,\n",
    "        temporal_strategy=args.temporal_strategy,\n",
    "        shuffle=split == \"train\",\n",
    "        num_workers=args.num_workers,\n",
    "        persistent_workers=args.num_workers > 0,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:26:53.584762Z",
     "start_time": "2024-03-14T09:26:46.574574Z"
    }
   },
   "id": "685443e8045bc6ba",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "edge_index_dict = {}\n",
    "for edge_type in data.edge_types:\n",
    "    edge_index_dict[edge_type] = data[edge_type].edge_index\n",
    "\n",
    "#print(\"edge types:\\n\",data.edge_types)\n",
    "\n",
    "x_dict = {}\n",
    "for node_type in data.node_types:\n",
    "    # Assuming data[node_type].tf.to_tensor() is the method to convert TensorFrame to a tensor.\n",
    "    # Adjust this method based on the actual implementation of TensorFrame.\n",
    "    x_dict[node_type] = data[node_type].tf.to_tensor() if hasattr(data[node_type].tf, 'to_tensor') else data[node_type].tf\n",
    "#print(x_dict)\n",
    "#print(\"node types:\\n\",data.node_types)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Your code that creates and starts processes should go here\n",
    "#     # This ensures that multiprocessing is handled correctly\n",
    "#     for batch in loader_dict[\"train\"]:\n",
    "#         batch = batch.to(device)\n",
    "#         print(\"batch:\\n\", batch)\n",
    "\n",
    "\n",
    "#print(\"task.train_table\\n\",task.train_table)\n",
    "#print(\"task.entity_table\\n\",task.entity_table)\n",
    "\n",
    "# print(\"table_input:\",table_input)\n",
    "# print(\"table_input.nodes:\",table_input.nodes)\n",
    "# print(\"table_input.nodes[0]:\",table_input.nodes[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T20:55:19.556080Z",
     "start_time": "2024-03-13T20:55:19.543636Z"
    }
   },
   "id": "c718996acb8d006e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2f0d50e15d1c8c7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TensorFrame(\n  num_cols=2,\n  num_rows=623967,\n  timestamp (1): ['CreationDate'],\n  embedding (1): ['Text'],\n  has_target=False,\n  device='cpu',\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentstf = data['comments'].tf\n",
    "commentstf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:44:16.580981Z",
     "start_time": "2024-03-14T09:44:16.508133Z"
    }
   },
   "id": "c0b9c40c8335f983",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "c_timestamp = list(commentstf.feat_dict.keys())[0]\n",
    "c_emb = list(commentstf.feat_dict.keys())[1]\n",
    "c_timetensors = commentstf.feat_dict[c_timestamp]\n",
    "c_embeddingtensors = commentstf.feat_dict[c_emb].values\n",
    "c_timetensors = c_timetensors.squeeze(1)  \n",
    "comments_features = torch.cat([c_timetensors, c_embeddingtensors], dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:44:18.132515Z",
     "start_time": "2024-03-14T09:44:17.749977Z"
    }
   },
   "id": "cf9393faca37c47e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "userstf = data['users'].tf\n",
    "u_numerical = list(userstf.feat_dict.keys())[0]\n",
    "u_timestamp = list(userstf.feat_dict.keys())[1]\n",
    "u_embedding = list(userstf.feat_dict.keys())[2]\n",
    "u_numtensors = userstf.feat_dict[u_numerical]\n",
    "u_timetensors = userstf.feat_dict[u_timestamp]\n",
    "u_embtensors = userstf.feat_dict[u_embedding].values\n",
    "users_features = torch.cat([u_numtensors,u_timetensors.squeeze(1),u_embtensors], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:44:19.855127Z",
     "start_time": "2024-03-14T09:44:19.699484Z"
    }
   },
   "id": "64a1826adf7942ec",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "badgestf = data['badges'].tf\n",
    "b_timestamp = list(badgestf.feat_dict.keys())[1]\n",
    "b_categorical = list(badgestf.feat_dict.keys())[0]\n",
    "b_timetensors = badgestf.feat_dict[b_timestamp]\n",
    "b_categoricaltensors = badgestf.feat_dict[b_categorical]\n",
    "badges_features = torch.cat([b_categoricaltensors,b_timetensors.squeeze(1)], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:48:01.885384Z",
     "start_time": "2024-03-14T09:48:01.842938Z"
    }
   },
   "id": "627efb079625c6ab",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "postLinkstf = data['postLinks'].tf\n",
    "pl_timestamp = list(postLinkstf.feat_dict.keys())[1]\n",
    "pl_numerical = list(postLinkstf.feat_dict.keys())[0]\n",
    "pl_timetensors = postLinkstf.feat_dict[pl_timestamp]\n",
    "pl_numericaltensors = postLinkstf.feat_dict[pl_numerical]\n",
    "postLinks_features = torch.cat([pl_numericaltensors,pl_timetensors.squeeze(1)], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:48:37.260269Z",
     "start_time": "2024-03-14T09:48:37.244964Z"
    }
   },
   "id": "74bb009a8ce341a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "postHistorytf = data['postHistory'].tf\n",
    "ph_numerical = list(postHistorytf.feat_dict.keys())[0]\n",
    "ph_categorical = list(postHistorytf.feat_dict.keys())[1]\n",
    "ph_timestamp = list(postHistorytf.feat_dict.keys())[2]\n",
    "ph_embedding = list(postHistorytf.feat_dict.keys())[3]\n",
    "ph_numtensors = postHistorytf.feat_dict[ph_numerical]\n",
    "ph_categoricaltensors = postHistorytf.feat_dict[ph_categorical]\n",
    "ph_timetensors = postHistorytf.feat_dict[ph_timestamp]\n",
    "ph_embtensors = postHistorytf.feat_dict[ph_embedding].values\n",
    "postHistory_features = torch.cat([ph_numtensors,ph_categoricaltensors,ph_timetensors.squeeze(1),ph_embtensors], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:48:57.397491Z",
     "start_time": "2024-03-14T09:48:55.856108Z"
    }
   },
   "id": "ba82eb1dafb1509b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "votestf = data['votes'].tf\n",
    "v_numerical = list(votestf.feat_dict.keys())[0]\n",
    "v_timestamp = list(votestf.feat_dict.keys())[1]\n",
    "v_numtensors = votestf.feat_dict[v_numerical]\n",
    "v_timetensors = votestf.feat_dict[v_timestamp]\n",
    "votes_features = torch.cat([v_numtensors,v_timetensors.squeeze(1)], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:49:15.328402Z",
     "start_time": "2024-03-14T09:49:15.211636Z"
    }
   },
   "id": "8eaf577436b9735",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "poststf = data['posts'].tf\n",
    "p_numerical = list(poststf.feat_dict.keys())[0]\n",
    "p_timestamp = list(poststf.feat_dict.keys())[1]\n",
    "p_embedding = list(poststf.feat_dict.keys())[2]\n",
    "p_numtensors = poststf.feat_dict[p_numerical]\n",
    "p_timetensors = poststf.feat_dict[p_timestamp]\n",
    "p_embtensors = poststf.feat_dict[p_embedding].values\n",
    "posts_features = torch.cat([p_numtensors,p_timetensors.squeeze(1),p_embtensors], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:49:35.905890Z",
     "start_time": "2024-03-14T09:49:34.196845Z"
    }
   },
   "id": "fa39ba34a2d48b7e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_dict = {\n",
    "    'comments': comments_features,\n",
    "    'badges': badges_features,\n",
    "    'postLinks': postLinks_features,\n",
    "    'postHistory': postHistory_features,\n",
    "    'votes': votes_features,\n",
    "    'users': users_features,\n",
    "    'posts': posts_features  \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:49:46.247135Z",
     "start_time": "2024-03-14T09:49:46.236172Z"
    }
   },
   "id": "82edeb66ee731dd3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([255360, 308])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict['users'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:49:47.435997Z",
     "start_time": "2024-03-14T09:49:47.393959Z"
    }
   },
   "id": "f00b9d852a9e2282",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgl_graph:\n",
      " Graph(num_nodes={'badges': 463463, 'comments': 623967, 'postHistory': 1175368, 'postLinks': 77337, 'posts': 333893, 'users': 255359, 'votes': 1317876},\n",
      "      num_edges={('badges', 'f2p_UserId', 'users'): 463463, ('comments', 'f2p_PostId', 'posts'): 623962, ('comments', 'f2p_UserId', 'users'): 612288, ('postHistory', 'f2p_PostId', 'posts'): 1175368, ('postHistory', 'f2p_UserId', 'users'): 1100031, ('postLinks', 'f2p_PostId', 'posts'): 61171, ('postLinks', 'f2p_RelatedPostId', 'posts'): 75588, ('posts', 'f2p_AcceptedAnswerId', 'posts'): 57714, ('posts', 'f2p_OwnerUserId', 'users'): 328648, ('posts', 'f2p_ParentId', 'posts'): 167355, ('posts', 'p2f_AcceptedAnswerId', 'posts'): 57714, ('posts', 'p2f_ParentId', 'posts'): 167355, ('posts', 'p2f_PostId', 'comments'): 623962, ('posts', 'p2f_PostId', 'postHistory'): 1175368, ('posts', 'p2f_PostId', 'postLinks'): 61171, ('posts', 'p2f_PostId', 'votes'): 1199831, ('posts', 'p2f_RelatedPostId', 'postLinks'): 75588, ('users', 'p2f_OwnerUserId', 'posts'): 328648, ('users', 'p2f_UserId', 'badges'): 463463, ('users', 'p2f_UserId', 'comments'): 612288, ('users', 'p2f_UserId', 'postHistory'): 1100031, ('users', 'p2f_UserId', 'votes'): 5182, ('votes', 'f2p_PostId', 'posts'): 1199831, ('votes', 'f2p_UserId', 'users'): 5182},\n",
      "      metagraph=[('badges', 'users', 'f2p_UserId'), ('users', 'posts', 'p2f_OwnerUserId'), ('users', 'badges', 'p2f_UserId'), ('users', 'comments', 'p2f_UserId'), ('users', 'postHistory', 'p2f_UserId'), ('users', 'votes', 'p2f_UserId'), ('comments', 'posts', 'f2p_PostId'), ('comments', 'users', 'f2p_UserId'), ('posts', 'posts', 'f2p_AcceptedAnswerId'), ('posts', 'posts', 'f2p_ParentId'), ('posts', 'posts', 'p2f_AcceptedAnswerId'), ('posts', 'posts', 'p2f_ParentId'), ('posts', 'users', 'f2p_OwnerUserId'), ('posts', 'comments', 'p2f_PostId'), ('posts', 'postHistory', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_RelatedPostId'), ('posts', 'votes', 'p2f_PostId'), ('postHistory', 'posts', 'f2p_PostId'), ('postHistory', 'users', 'f2p_UserId'), ('postLinks', 'posts', 'f2p_PostId'), ('postLinks', 'posts', 'f2p_RelatedPostId'), ('votes', 'posts', 'f2p_PostId'), ('votes', 'users', 'f2p_UserId')])\n",
      "dgl_graph.nodes['users']:\n",
      " NodeSpace(data={})\n"
     ]
    }
   ],
   "source": [
    "graph_data = {}\n",
    "\n",
    "# For each edge type in the HeteroData\n",
    "for (src_type, edge_type, dst_type), edge_data in data.edge_index_dict.items():\n",
    "    src_nodes, dst_nodes = edge_data\n",
    "    # Convert PyG edge index format to DGL format\n",
    "    graph_data[(src_type, edge_type, dst_type)] = (src_nodes.numpy(), dst_nodes.numpy())\n",
    "\n",
    "# Create the DGL heterograph\n",
    "dgl_graph = dgl.heterograph(graph_data)\n",
    "print(\"dgl_graph:\\n\",dgl_graph)\n",
    "print(\"dgl_graph.nodes['users']:\\n\",dgl_graph.nodes['users'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:31:17.678095Z",
     "start_time": "2024-03-14T09:31:16.425579Z"
    }
   },
   "id": "4b419a19e19a7608",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{('comments',\n  'f2p_UserId',\n  'users'): (array([     2,      5,      9, ..., 623964, 623965, 623966], dtype=int64), array([   957,    884,    957, ..., 249015, 126602,   1872], dtype=int64)),\n ('users',\n  'p2f_UserId',\n  'comments'): (array([     2,      4,      4, ..., 255334, 255347, 255351], dtype=int64), array([ 34710,     43,     57, ..., 623941, 623944, 623957], dtype=int64)),\n ('comments',\n  'f2p_PostId',\n  'posts'): (array([     0,      1,      2, ..., 623964, 623965, 623966], dtype=int64), array([     1,      1,      1, ..., 333879, 333879, 333437], dtype=int64)),\n ('posts',\n  'p2f_PostId',\n  'comments'): (array([     0,      0,      0, ..., 333881, 333881, 333883], dtype=int64), array([413710, 413713, 559727, ..., 623961, 623962, 623958], dtype=int64)),\n ('badges',\n  'f2p_UserId',\n  'users'): (array([     0,      1,      2, ..., 463460, 463461, 463462], dtype=int64), array([     4,      5,      7, ..., 253733, 255356, 255358], dtype=int64)),\n ('users',\n  'p2f_UserId',\n  'badges'): (array([     1,      1,      1, ..., 255356, 255356, 255358], dtype=int64), array([    46,   1505,   3590, ..., 463457, 463461, 463462], dtype=int64)),\n ('postLinks',\n  'f2p_PostId',\n  'posts'): (array([    0,     1,     3, ..., 77334, 77335, 77336], dtype=int64), array([   386,    534,    368, ...,  65040, 333880, 333872], dtype=int64)),\n ('posts',\n  'p2f_PostId',\n  'postLinks'): (array([    26,     28,     28, ..., 333871, 333872, 333880], dtype=int64), array([  515,  1875, 25335, ..., 77333, 77336, 77335], dtype=int64)),\n ('postLinks',\n  'f2p_RelatedPostId',\n  'posts'): (array([    0,     1,     2, ..., 77334, 77335, 77336], dtype=int64), array([   179,    525,    575, ..., 333498, 233168, 301954], dtype=int64)),\n ('posts',\n  'p2f_RelatedPostId',\n  'postLinks'): (array([     9,     23,     23, ..., 333720, 333772, 333811], dtype=int64), array([15648,   113,   258, ..., 77293, 77295, 77323], dtype=int64)),\n ('postHistory',\n  'f2p_PostId',\n  'posts'): (array([      0,       1,       2, ..., 1175365, 1175366, 1175367],\n        dtype=int64), array([     0,      0,      0, ..., 333891, 333891, 333892], dtype=int64)),\n ('posts',\n  'p2f_PostId',\n  'postHistory'): (array([     0,      0,      0, ..., 333891, 333891, 333892], dtype=int64), array([      0,       1,       2, ..., 1175365, 1175366, 1175367],\n        dtype=int64)),\n ('postHistory',\n  'f2p_UserId',\n  'users'): (array([      0,       1,       2, ..., 1175365, 1175366, 1175367],\n        dtype=int64), array([ 76449,  76449,  76449, ..., 211410, 211410, 255358], dtype=int64)),\n ('users',\n  'p2f_UserId',\n  'postHistory'): (array([     0,      0,      0, ..., 255354, 255354, 255358], dtype=int64), array([     45,      53,      63, ..., 1175351, 1175352, 1175367],\n        dtype=int64)),\n ('votes',\n  'f2p_PostId',\n  'posts'): (array([      0,       1,       2, ..., 1317873, 1317874, 1317875],\n        dtype=int64), array([     2,      6,      6, ..., 217931, 255319, 232649], dtype=int64)),\n ('posts',\n  'p2f_PostId',\n  'votes'): (array([     0,      0,      0, ..., 333888, 333891, 333892], dtype=int64), array([     23,      24,      25, ..., 1317823, 1317700, 1317759],\n        dtype=int64)),\n ('votes',\n  'f2p_UserId',\n  'users'): (array([   1496,    2114,    3004, ..., 1316844, 1317248, 1317263],\n        dtype=int64), array([    50,    166,    166, ...,   5237, 237981, 141531], dtype=int64)),\n ('users',\n  'p2f_UserId',\n  'votes'): (array([     0,      0,      0, ..., 252504, 252682, 254662], dtype=int64), array([  77034,   83838,   85094, ..., 1310896, 1312798, 1315892],\n        dtype=int64)),\n ('posts',\n  'f2p_OwnerUserId',\n  'users'): (array([     0,      1,      3, ..., 333890, 333891, 333892], dtype=int64), array([ 76449,    957,    884, ..., 216615, 211410, 255358], dtype=int64)),\n ('users',\n  'p2f_OwnerUserId',\n  'posts'): (array([     0,      0,      0, ..., 255341, 255354, 255358], dtype=int64), array([  2045,   7837,   8188, ..., 333869, 333886, 333892], dtype=int64)),\n ('posts',\n  'f2p_ParentId',\n  'posts'): (array([     1,      2,      3, ..., 333889, 333890, 333892], dtype=int64), array([     0,      0,      0, ..., 332888, 320669,  27860], dtype=int64)),\n ('posts',\n  'p2f_ParentId',\n  'posts'): (array([     0,      0,      0, ..., 333873, 333877, 333880], dtype=int64), array([     1,      2,      3, ..., 333875, 333878, 333881], dtype=int64)),\n ('posts',\n  'f2p_AcceptedAnswerId',\n  'posts'): (array([     0,      9,     16, ..., 333873, 333877, 333880], dtype=int64), array([     1,     13,     17, ..., 333875, 333878, 333881], dtype=int64)),\n ('posts',\n  'p2f_AcceptedAnswerId',\n  'posts'): (array([     1,     13,     17, ..., 333881, 333882, 333884], dtype=int64), array([     0,      9,     16, ..., 333880, 333832, 333872], dtype=int64))}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:32:07.673242Z",
     "start_time": "2024-03-14T09:32:07.628603Z"
    }
   },
   "id": "9f5e284429a0fbd6",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = torch.load(\"C:\\\\Users\\\\Shreya Reddy\\\\Downloads\\\\relbenchmain\\\\examples\\\\saved_model.pth\",\n",
    "                   map_location=torch.device('cpu'))\n",
    "explainer = HeteroGNNExplainer(model, num_hops=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:38:19.965319Z",
     "start_time": "2024-03-14T03:38:19.733706Z"
    }
   },
   "id": "fce092ddecd04851",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[186], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdgl_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\nn\\pytorch\\explain\\gnnexplainer.py:898\u001B[0m, in \u001B[0;36mHeteroGNNExplainer.explain_graph\u001B[1;34m(self, graph, feat, **kwargs)\u001B[0m\n\u001B[0;32m    896\u001B[0m \u001B[38;5;66;03m# Get the initial prediction.\u001B[39;00m\n\u001B[0;32m    897\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 898\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(graph\u001B[38;5;241m=\u001B[39mgraph, feat\u001B[38;5;241m=\u001B[39mfeat, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    899\u001B[0m     pred_label \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    901\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_masks(graph, feat)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'graph'"
     ]
    }
   ],
   "source": [
    "feat_mask, edge_mask = explainer.explain_graph(dgl_graph, feature_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:38:23.947680Z",
     "start_time": "2024-03-14T03:38:22.840444Z"
    }
   },
   "id": "dd0536e02f573b7f",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import HeteroGNNExplainer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:48:45.030385Z",
     "start_time": "2024-03-14T03:48:45.013332Z"
    }
   },
   "id": "bfbe49e597e04497",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes, canonical_etypes, ntype_feature_sizes):\n",
    "        super(Model, self).__init__()\n",
    "        # Initialize ModuleDict for edge type specific linear transformations\n",
    "        self.etype_weights = nn.ModuleDict({\n",
    "            '_'.join(c_etype): nn.Linear(ntype_feature_sizes[c_etype[0]], num_classes)\n",
    "            for c_etype in canonical_etypes\n",
    "        })\n",
    "\n",
    "    def forward(self, graph, feat, eweight=None):\n",
    "        feat = {ntype: f.float() for ntype, f in feat.items()}\n",
    "        with graph.local_scope():\n",
    "            c_etype_func_dict = {}\n",
    "            for c_etype in graph.canonical_etypes:\n",
    "                src_type, etype, dst_type = c_etype\n",
    "                # Apply linear transformation based on edge type\n",
    "                wh = self.etype_weights['_'.join(c_etype)](feat[src_type])\n",
    "                graph.nodes[src_type].data[f'h_{c_etype}'] = wh\n",
    "                \n",
    "                # Define message and reduce functions based on whether edge weights are provided\n",
    "                if eweight is None:\n",
    "                    c_etype_func_dict[c_etype] = (fn.copy_u(f'h_{c_etype}', 'm'), fn.mean('m', 'h'))\n",
    "                else:\n",
    "                    graph.edges[c_etype].data['w'] = eweight[c_etype]\n",
    "                    c_etype_func_dict[c_etype] = (fn.u_mul_e(f'h_{c_etype}', 'w', 'm'), fn.mean('m', 'h'))\n",
    "            \n",
    "            # Update all nodes based on the defined message and reduce functions\n",
    "            graph.multi_update_all(c_etype_func_dict, 'sum')\n",
    "            \n",
    "            # Aggregate node features across all node types\n",
    "            hg = 0\n",
    "            for ntype in graph.ntypes:\n",
    "                if graph.num_nodes(ntype):\n",
    "                    hg += dgl.mean_nodes(graph, 'h', ntype=ntype)\n",
    "            return hg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:12:29.247579Z",
     "start_time": "2024-03-14T04:12:29.233702Z"
    }
   },
   "id": "ac16e627c0289c2d",
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "num_classes = 2\n",
    "g = dgl.heterograph({\n",
    "    ('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 1, 1])})\n",
    "g.nodes['user'].data['h'] = th.randn(g.num_nodes('user'), input_dim)\n",
    "g.nodes['game'].data['h'] = th.randn(g.num_nodes('game'), input_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:49:08.425246Z",
     "start_time": "2024-03-14T03:49:08.379596Z"
    }
   },
   "id": "ab474f617aa41339",
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'game': 2, 'user': 3},\n      num_edges={('game', 'rev_plays', 'user'): 4, ('user', 'plays', 'game'): 4},\n      metagraph=[('game', 'user', 'rev_plays'), ('user', 'game', 'plays')])"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:50:11.871831Z",
     "start_time": "2024-03-14T03:50:11.852603Z"
    }
   },
   "id": "522b028189e37d8c",
   "execution_count": 198
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'badges': 463463, 'comments': 623967, 'postHistory': 1175368, 'postLinks': 77337, 'posts': 333893, 'users': 255359, 'votes': 1317876},\n      num_edges={('badges', 'f2p_UserId', 'users'): 463463, ('comments', 'f2p_PostId', 'posts'): 623962, ('comments', 'f2p_UserId', 'users'): 612288, ('postHistory', 'f2p_PostId', 'posts'): 1175368, ('postHistory', 'f2p_UserId', 'users'): 1100031, ('postLinks', 'f2p_PostId', 'posts'): 61171, ('postLinks', 'f2p_RelatedPostId', 'posts'): 75588, ('posts', 'f2p_AcceptedAnswerId', 'posts'): 57714, ('posts', 'f2p_OwnerUserId', 'users'): 328648, ('posts', 'f2p_ParentId', 'posts'): 167355, ('posts', 'p2f_AcceptedAnswerId', 'posts'): 57714, ('posts', 'p2f_ParentId', 'posts'): 167355, ('posts', 'p2f_PostId', 'comments'): 623962, ('posts', 'p2f_PostId', 'postHistory'): 1175368, ('posts', 'p2f_PostId', 'postLinks'): 61171, ('posts', 'p2f_PostId', 'votes'): 1199831, ('posts', 'p2f_RelatedPostId', 'postLinks'): 75588, ('users', 'p2f_OwnerUserId', 'posts'): 328648, ('users', 'p2f_UserId', 'badges'): 463463, ('users', 'p2f_UserId', 'comments'): 612288, ('users', 'p2f_UserId', 'postHistory'): 1100031, ('users', 'p2f_UserId', 'votes'): 5182, ('votes', 'f2p_PostId', 'posts'): 1199831, ('votes', 'f2p_UserId', 'users'): 5182},\n      metagraph=[('badges', 'users', 'f2p_UserId'), ('users', 'posts', 'p2f_OwnerUserId'), ('users', 'badges', 'p2f_UserId'), ('users', 'comments', 'p2f_UserId'), ('users', 'postHistory', 'p2f_UserId'), ('users', 'votes', 'p2f_UserId'), ('comments', 'posts', 'f2p_PostId'), ('comments', 'users', 'f2p_UserId'), ('posts', 'posts', 'f2p_AcceptedAnswerId'), ('posts', 'posts', 'f2p_ParentId'), ('posts', 'posts', 'p2f_AcceptedAnswerId'), ('posts', 'posts', 'p2f_ParentId'), ('posts', 'users', 'f2p_OwnerUserId'), ('posts', 'comments', 'p2f_PostId'), ('posts', 'postHistory', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_RelatedPostId'), ('posts', 'votes', 'p2f_PostId'), ('postHistory', 'posts', 'f2p_PostId'), ('postHistory', 'users', 'f2p_UserId'), ('postLinks', 'posts', 'f2p_PostId'), ('postLinks', 'posts', 'f2p_RelatedPostId'), ('votes', 'posts', 'f2p_PostId'), ('votes', 'users', 'f2p_UserId')])"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:50:23.260047Z",
     "start_time": "2024-03-14T03:50:23.244729Z"
    }
   },
   "id": "5144800b633208e5",
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'game': tensor([[-0.1195,  0.2537, -0.3454, -0.6362, -0.4492],\n         [ 1.8029,  1.0797,  1.1765,  1.3234, -0.6570]]),\n 'user': tensor([[ 0.2359,  0.0094, -0.5826, -2.0033,  1.0364],\n         [-0.4612, -1.1405, -0.7990,  0.0546, -0.3133],\n         [ 0.6679,  0.7529, -1.2330,  1.2736,  0.2938]])}"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['h']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:51:32.518932Z",
     "start_time": "2024-03-14T03:51:32.491629Z"
    }
   },
   "id": "7c77594d6b1f6b72",
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'comments': tensor([[ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -3.2116e-01,\n          -1.0238e-01,  6.1823e-02],\n         [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.0727e-02,\n          -3.2732e-03,  5.0768e-02],\n         [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.7929e-02,\n           1.2871e-01, -1.6217e-01],\n         ...,\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.8093e-01,\n          -4.8019e-02, -1.4107e-01],\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.1969e-01,\n           1.0899e-01, -7.9156e-03],\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.4080e-01,\n          -1.0459e-01, -3.6677e-02]]),\n 'badges': tensor([[   0,    0, 2010,  ...,   19,   39,    7],\n         [   0,    0, 2010,  ...,   19,   39,    7],\n         [   0,    0, 2010,  ...,   19,   39,    7],\n         ...,\n         [   0,    0, 2020,  ...,   22,   57,   30],\n         [   0,    0, 2020,  ...,   23,   40,   12],\n         [   0,    0, 2020,  ...,   23,   55,    3]]),\n 'postLinks': tensor([[1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.4000e+01, 4.7000e+01,\n          3.3000e+01],\n         [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.6000e+01, 3.0000e+01,\n          4.1000e+01],\n         [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 9.0000e+00, 1.1000e+01,\n          1.0000e+00],\n         ...,\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 1.9000e+01, 3.1000e+01,\n          5.9000e+01],\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.0000e+01,\n          3.9000e+01],\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.5000e+01,\n          2.4000e+01]]),\n 'postHistory': tensor([[ 1.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -1.4295e-01,\n          -1.0796e-01,  7.9543e-02],\n         [ 2.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -2.6364e-01,\n           7.6387e-02,  7.1052e-02],\n         [ 3.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -5.2986e-01,\n           9.9912e-03,  7.9939e-02],\n         ...,\n         [ 1.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -1.9610e-01,\n           2.3302e-01,  1.0279e-01],\n         [ 3.0000e+00,  1.0000e+00,  2.0200e+03,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00],\n         [ 2.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -3.6696e-02,\n           1.1555e-01, -2.8800e-02]]),\n 'votes': tensor([[2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         ...,\n         [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [1.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00]]),\n 'users': tensor([[-1.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -4.6642e-02,\n          -2.3646e-01,  3.8098e-02],\n         [ 2.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -1.3502e-01,\n          -4.5602e-02, -2.6330e-02],\n         [ 3.0000e+00,  2.0100e+03,  6.0000e+00,  ...,  5.9934e-02,\n          -1.8164e-01, -1.0005e-01],\n         ...,\n         [ 1.7282e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 2.0342e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 4.3574e+06,  2.0200e+03,  1.1000e+01,  ...,  3.3679e-01,\n           1.9018e-02, -5.6008e-02]]),\n 'posts': tensor([[ 1.0000e+00,  2.0090e+03,  1.0000e+00,  ..., -1.4295e-01,\n          -1.0796e-01,  7.9543e-02],\n         [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         ...,\n         [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 1.0000e+00,  2.0200e+03,  1.1000e+01,  ..., -1.9610e-01,\n           2.3302e-01,  1.0279e-01],\n         [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01]])}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:32:21.819933Z",
     "start_time": "2024-03-14T09:32:21.797773Z"
    }
   },
   "id": "b1007b4b7a35f7f8",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = dgl.transforms.AddReverse()\n",
    "g = transform(g)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:49:24.565568Z",
     "start_time": "2024-03-14T03:49:24.518433Z"
    }
   },
   "id": "86f67cf5df7921c1",
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = dgl.transforms.AddReverse()\n",
    "dgl_graph_t = transform(dgl_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:09:38.638343Z",
     "start_time": "2024-03-14T04:09:38.464118Z"
    }
   },
   "id": "f1f40e7a8f370ce7",
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define and train the model\n",
    "model = Model(input_dim, num_classes, g.canonical_etypes)\n",
    "feat = g.ndata['h']\n",
    "optimizer = th.optim.Adam(model.parameters())\n",
    "for epoch in range(10):\n",
    "    logits = model(g, feat)\n",
    "    loss = F.cross_entropy(logits, th.tensor([1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:49:26.232875Z",
     "start_time": "2024-03-14T03:49:25.200295Z"
    }
   },
   "id": "df57f13c79a985e6",
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'game': 2, 'user': 3},\n      num_edges={('game', 'rev_plays', 'user'): 4, ('user', 'plays', 'game'): 4},\n      metagraph=[('game', 'user', 'rev_plays'), ('user', 'game', 'plays')])"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:10:24.080946Z",
     "start_time": "2024-03-14T04:10:24.067495Z"
    }
   },
   "id": "ceafe9b46c8dc89",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'game': tensor([[-0.1195,  0.2537, -0.3454, -0.6362, -0.4492],\n         [ 1.8029,  1.0797,  1.1765,  1.3234, -0.6570]]),\n 'user': tensor([[ 0.2359,  0.0094, -0.5826, -2.0033,  1.0364],\n         [-0.4612, -1.1405, -0.7990,  0.0546, -0.3133],\n         [ 0.6679,  0.7529, -1.2330,  1.2736,  0.2938]])}"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['h']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:10:45.621734Z",
     "start_time": "2024-03-14T04:10:45.607806Z"
    }
   },
   "id": "15ddb988eeb74b2f",
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for ntype in feature_dict:\n",
    "    feature_dict[ntype] = feature_dict[ntype].float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:14:33.731518Z",
     "start_time": "2024-03-14T04:14:33.677148Z"
    }
   },
   "id": "2a5f71e8ff3c4c31",
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 255360 and 255359 instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDGLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[220], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters())\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 6\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdgl_graph_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(logits, th\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m1\u001B[39m]))\n\u001B[0;32m      8\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[217], line 18\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, graph, feat, eweight)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Apply linear transformation based on edge type\u001B[39;00m\n\u001B[0;32m     17\u001B[0m wh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39metype_weights[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c_etype)](feat[src_type])\n\u001B[1;32m---> 18\u001B[0m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43msrc_type\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mh_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mc_etype\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m wh\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Define message and reduce functions based on whether edge weights are provided\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eweight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\view.py:99\u001B[0m, in \u001B[0;36mHeteroNodeDataView.__setitem__\u001B[1;34m(self, key, val)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(val, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, (\n\u001B[0;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe HeteroNodeDataView has only one node type. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     97\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease pass a tensor directly\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     98\u001B[0m     )\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_n_repr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ntid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\heterograph.py:4344\u001B[0m, in \u001B[0;36mDGLGraph._set_n_repr\u001B[1;34m(self, ntid, u, data)\u001B[0m\n\u001B[0;32m   4342\u001B[0m nfeats \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mshape(val)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   4343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nfeats \u001B[38;5;241m!=\u001B[39m num_nodes:\n\u001B[1;32m-> 4344\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DGLError(\n\u001B[0;32m   4345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpect number of features to match number of nodes (len(u)).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4346\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Got \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (nfeats, num_nodes)\n\u001B[0;32m   4347\u001B[0m     )\n\u001B[0;32m   4348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m F\u001B[38;5;241m.\u001B[39mcontext(val) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice:\n\u001B[0;32m   4349\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DGLError(\n\u001B[0;32m   4350\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot assign node feature \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m on device \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m to a graph on\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   4351\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m device \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. Call DGLGraph.to() to copy the graph to the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4352\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m same device.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(key, F\u001B[38;5;241m.\u001B[39mcontext(val), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   4353\u001B[0m     )\n",
      "\u001B[1;31mDGLError\u001B[0m: Expect number of features to match number of nodes (len(u)). Got 255360 and 255359 instead."
     ]
    }
   ],
   "source": [
    "# define and train the model\n",
    "model = Model(2, dgl_graph_t.canonical_etypes, ntype_feature_sizes)\n",
    "feat = feature_dict\n",
    "# Trim the 'users' feature tensor\n",
    "feat['users'] = feat['users'][:dgl_graph_t.num_nodes('users')]\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:14:50.667133Z",
     "start_time": "2024-03-14T04:14:43.395500Z"
    }
   },
   "id": "9b4068eab50c43ba",
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1])"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.tensor([1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:09:37.126740Z",
     "start_time": "2024-03-14T05:09:37.080276Z"
    }
   },
   "id": "eac18d790def40a3",
   "execution_count": 232
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    logits = model(dgl_graph_t, feat)\n",
    "    loss = F.cross_entropy(logits, th.tensor([1]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:03:56.281747Z",
     "start_time": "2024-03-14T05:02:42.564434Z"
    }
   },
   "id": "5d0ab782240b90ed",
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|| 100/100 [00:02<00:00, 42.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Explain for the graph\n",
    "explainer = HeteroGNNExplainer(model, num_hops=1)\n",
    "feat_mask, edge_mask = explainer.explain_graph(g, feat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:49:48.271459Z",
     "start_time": "2024-03-14T03:49:45.889563Z"
    }
   },
   "id": "7f2204b350b69cba",
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[241], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_node\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43musers\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdgl_graph_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeat\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\nn\\pytorch\\explain\\gnnexplainer.py:746\u001B[0m, in \u001B[0;36mHeteroGNNExplainer.explain_node\u001B[1;34m(self, ntype, node_id, graph, feat, **kwargs)\u001B[0m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;66;03m# Get the initial prediction.\u001B[39;00m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 746\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msg_feat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mntype\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    747\u001B[0m     pred_label \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    749\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_masks(sg, sg_feat)\n",
      "\u001B[1;31mIndexError\u001B[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "explainer.explain_node('users', 2, dgl_graph_t, feat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:31:34.651659Z",
     "start_time": "2024-03-14T05:31:33.710674Z"
    }
   },
   "id": "1fe057590be4bdab",
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph:   0%|          | 0/100 [19:09<?, ?it/s]\n",
      "Explain graph:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1212699376 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[236], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()  \u001B[38;5;66;03m# If using GPU\u001B[39;00m\n\u001B[0;32m      4\u001B[0m explainer \u001B[38;5;241m=\u001B[39m HeteroGNNExplainer(model, num_hops\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdgl_graph_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeat\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\nn\\pytorch\\explain\\gnnexplainer.py:914\u001B[0m, in \u001B[0;36mHeteroGNNExplainer.explain_graph\u001B[1;34m(self, graph, feat, **kwargs)\u001B[0m\n\u001B[0;32m    912\u001B[0m h \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node_type, node_feat \u001B[38;5;129;01min\u001B[39;00m feat\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 914\u001B[0m     h[node_type] \u001B[38;5;241m=\u001B[39m \u001B[43mnode_feat\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfeat_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnode_type\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    915\u001B[0m eweight \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m canonical_etype, canonical_etype_mask \u001B[38;5;129;01min\u001B[39;00m edge_mask\u001B[38;5;241m.\u001B[39mitems():\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1212699376 bytes."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # If using GPU\n",
    "explainer = HeteroGNNExplainer(model, num_hops=1)\n",
    "feat_mask, edge_mask = explainer.explain_graph(dgl_graph_t, feat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:26:24.306652Z",
     "start_time": "2024-03-14T05:26:09.249229Z"
    }
   },
   "id": "4d93e23edc86f3a",
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'game': tensor([0.2701, 0.2751, 0.2891, 0.2709, 0.2584]),\n 'user': tensor([0.2388, 0.2607, 0.2523, 0.2926, 0.2674])}"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:49:56.957901Z",
     "start_time": "2024-03-14T03:49:56.942555Z"
    }
   },
   "id": "ce097c8f4ac47f7e",
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{('game', 'rev_plays', 'user'): tensor([0.2376, 0.9426, 0.0731, 0.0854]),\n ('user', 'plays', 'game'): tensor([0.9453, 0.7330, 0.7705, 0.9033])}"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T03:50:00.859300Z",
     "start_time": "2024-03-14T03:50:00.838332Z"
    }
   },
   "id": "b75565b7bddc567c",
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments\n",
      "torch.Size([623967, 307])\n",
      "badges\n",
      "torch.Size([463463, 9])\n",
      "postLinks\n",
      "torch.Size([77337, 8])\n",
      "postHistory\n",
      "torch.Size([1175368, 309])\n",
      "votes\n",
      "torch.Size([1317876, 8])\n",
      "users\n",
      "torch.Size([255360, 308])\n",
      "posts\n",
      "torch.Size([333893, 908])\n"
     ]
    }
   ],
   "source": [
    "for n in data.node_types:\n",
    "    print(n)\n",
    "    print(feature_dict[n].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:00:54.390039Z",
     "start_time": "2024-03-14T04:00:54.376617Z"
    }
   },
   "id": "6420ed908ee7cded",
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node type: badges, Number of nodes: 463463\n",
      "Node type: comments, Number of nodes: 623967\n",
      "Node type: postHistory, Number of nodes: 1175368\n",
      "Node type: postLinks, Number of nodes: 77337\n",
      "Node type: posts, Number of nodes: 333893\n",
      "Node type: users, Number of nodes: 255359\n",
      "Node type: votes, Number of nodes: 1317876\n"
     ]
    }
   ],
   "source": [
    "for ntype in dgl_graph_t.ntypes:\n",
    "    print(f\"Node type: {ntype}, Number of nodes: {dgl_graph_t.num_nodes(ntype)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:51:24.340471Z",
     "start_time": "2024-03-14T04:51:24.255886Z"
    }
   },
   "id": "107ce57e0a01c9bb",
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node type: comments, Feature shape: torch.Size([623967, 307])\n",
      "Node type: badges, Feature shape: torch.Size([463463, 9])\n",
      "Node type: postLinks, Feature shape: torch.Size([77337, 8])\n",
      "Node type: postHistory, Feature shape: torch.Size([1175368, 309])\n",
      "Node type: votes, Feature shape: torch.Size([1317876, 8])\n",
      "Node type: users, Feature shape: torch.Size([255359, 308])\n",
      "Node type: posts, Feature shape: torch.Size([333893, 908])\n"
     ]
    }
   ],
   "source": [
    "for ntype, feat_tensor in feat.items():\n",
    "    print(f\"Node type: {ntype}, Feature shape: {feat_tensor.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:01:51.800243Z",
     "start_time": "2024-03-14T05:01:51.788484Z"
    }
   },
   "id": "9ef1c7f692ff7336",
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Trim the 'users' feature tensor\n",
    "feat['users'] = feat['users'][:dgl_graph_t.num_nodes('users')]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:01:35.882809Z",
     "start_time": "2024-03-14T05:01:35.866803Z"
    }
   },
   "id": "cf435f63f3b71a9c",
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID for 'user' with unique ID 2: 1\n"
     ]
    }
   ],
   "source": [
    "# Assuming `feat` is a dictionary of features with keys as node types\n",
    "# and you're looking for a 'user' node with a specific feature value\n",
    "user_features = feat['users']  # Get features for 'user' nodes\n",
    "\n",
    "# Hypothetical condition to identify the specific user node,\n",
    "# e.g., the first feature is a unique ID, and you're looking for ID == some_unique_id\n",
    "some_unique_id = 2  # The unique ID or feature you're looking for\n",
    "node_ids = torch.where(user_features[:, 0] == some_unique_id)[0]  # Find node(s) with the ID\n",
    "\n",
    "if len(node_ids) > 0:\n",
    "    node_id = node_ids[0].item()  # Assuming the ID is unique and only one match is expected\n",
    "    print(f\"Node ID for 'user' with unique ID {some_unique_id}: {node_id}\")\n",
    "else:\n",
    "    print(f\"No 'user' node found with unique ID {some_unique_id}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:28:28.431438Z",
     "start_time": "2024-03-14T05:28:28.417320Z"
    }
   },
   "id": "a3342ffd51d7e388",
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -4.6642e-02,\n         -2.3646e-01,  3.8098e-02],\n        [ 2.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -1.3502e-01,\n         -4.5602e-02, -2.6330e-02],\n        [ 3.0000e+00,  2.0100e+03,  6.0000e+00,  ...,  5.9934e-02,\n         -1.8164e-01, -1.0005e-01],\n        ...,\n        [ 2.0341e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n         -2.2297e-01,  3.0119e-01],\n        [ 1.7282e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n         -2.2297e-01,  3.0119e-01],\n        [ 2.0342e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n         -2.2297e-01,  3.0119e-01]])"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:28:00.570840Z",
     "start_time": "2024-03-14T05:28:00.547665Z"
    }
   },
   "id": "cb2ca398c3b1558",
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ntype_feature_sizes = {\n",
    "    'comments': 307,\n",
    "    'badges': 9,\n",
    "    'postLinks': 8,\n",
    "    'postHistory': 309,\n",
    "    'votes': 8,\n",
    "    'users': 308,\n",
    "    'posts': 908,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:06:12.366597Z",
     "start_time": "2024-03-14T04:06:12.358664Z"
    }
   },
   "id": "36dde9a00f392c3",
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{('comments',\n  'f2p_UserId',\n  'users'): tensor([[     2,      5,      9,  ..., 623964, 623965, 623966],\n         [   957,    884,    957,  ..., 249015, 126602,   1872]]),\n ('users',\n  'p2f_UserId',\n  'comments'): tensor([[     2,      4,      4,  ..., 255334, 255347, 255351],\n         [ 34710,     43,     57,  ..., 623941, 623944, 623957]]),\n ('comments',\n  'f2p_PostId',\n  'posts'): tensor([[     0,      1,      2,  ..., 623964, 623965, 623966],\n         [     1,      1,      1,  ..., 333879, 333879, 333437]]),\n ('posts',\n  'p2f_PostId',\n  'comments'): tensor([[     0,      0,      0,  ..., 333881, 333881, 333883],\n         [413710, 413713, 559727,  ..., 623961, 623962, 623958]]),\n ('badges',\n  'f2p_UserId',\n  'users'): tensor([[     0,      1,      2,  ..., 463460, 463461, 463462],\n         [     4,      5,      7,  ..., 253733, 255356, 255358]]),\n ('users',\n  'p2f_UserId',\n  'badges'): tensor([[     1,      1,      1,  ..., 255356, 255356, 255358],\n         [    46,   1505,   3590,  ..., 463457, 463461, 463462]]),\n ('postLinks',\n  'f2p_PostId',\n  'posts'): tensor([[     0,      1,      3,  ...,  77334,  77335,  77336],\n         [   386,    534,    368,  ...,  65040, 333880, 333872]]),\n ('posts',\n  'p2f_PostId',\n  'postLinks'): tensor([[    26,     28,     28,  ..., 333871, 333872, 333880],\n         [   515,   1875,  25335,  ...,  77333,  77336,  77335]]),\n ('postLinks',\n  'f2p_RelatedPostId',\n  'posts'): tensor([[     0,      1,      2,  ...,  77334,  77335,  77336],\n         [   179,    525,    575,  ..., 333498, 233168, 301954]]),\n ('posts',\n  'p2f_RelatedPostId',\n  'postLinks'): tensor([[     9,     23,     23,  ..., 333720, 333772, 333811],\n         [ 15648,    113,    258,  ...,  77293,  77295,  77323]]),\n ('postHistory',\n  'f2p_PostId',\n  'posts'): tensor([[      0,       1,       2,  ..., 1175365, 1175366, 1175367],\n         [      0,       0,       0,  ...,  333891,  333891,  333892]]),\n ('posts',\n  'p2f_PostId',\n  'postHistory'): tensor([[      0,       0,       0,  ...,  333891,  333891,  333892],\n         [      0,       1,       2,  ..., 1175365, 1175366, 1175367]]),\n ('postHistory',\n  'f2p_UserId',\n  'users'): tensor([[      0,       1,       2,  ..., 1175365, 1175366, 1175367],\n         [  76449,   76449,   76449,  ...,  211410,  211410,  255358]]),\n ('users',\n  'p2f_UserId',\n  'postHistory'): tensor([[      0,       0,       0,  ...,  255354,  255354,  255358],\n         [     45,      53,      63,  ..., 1175351, 1175352, 1175367]]),\n ('votes',\n  'f2p_PostId',\n  'posts'): tensor([[      0,       1,       2,  ..., 1317873, 1317874, 1317875],\n         [      2,       6,       6,  ...,  217931,  255319,  232649]]),\n ('posts',\n  'p2f_PostId',\n  'votes'): tensor([[      0,       0,       0,  ...,  333888,  333891,  333892],\n         [     23,      24,      25,  ..., 1317823, 1317700, 1317759]]),\n ('votes',\n  'f2p_UserId',\n  'users'): tensor([[   1496,    2114,    3004,  ..., 1316844, 1317248, 1317263],\n         [     50,     166,     166,  ...,    5237,  237981,  141531]]),\n ('users',\n  'p2f_UserId',\n  'votes'): tensor([[      0,       0,       0,  ...,  252504,  252682,  254662],\n         [  77034,   83838,   85094,  ..., 1310896, 1312798, 1315892]]),\n ('posts',\n  'f2p_OwnerUserId',\n  'users'): tensor([[     0,      1,      3,  ..., 333890, 333891, 333892],\n         [ 76449,    957,    884,  ..., 216615, 211410, 255358]]),\n ('users',\n  'p2f_OwnerUserId',\n  'posts'): tensor([[     0,      0,      0,  ..., 255341, 255354, 255358],\n         [  2045,   7837,   8188,  ..., 333869, 333886, 333892]]),\n ('posts',\n  'f2p_ParentId',\n  'posts'): tensor([[     1,      2,      3,  ..., 333889, 333890, 333892],\n         [     0,      0,      0,  ..., 332888, 320669,  27860]]),\n ('posts',\n  'p2f_ParentId',\n  'posts'): tensor([[     0,      0,      0,  ..., 333873, 333877, 333880],\n         [     1,      2,      3,  ..., 333875, 333878, 333881]]),\n ('posts',\n  'f2p_AcceptedAnswerId',\n  'posts'): tensor([[     0,      9,     16,  ..., 333873, 333877, 333880],\n         [     1,     13,     17,  ..., 333875, 333878, 333881]]),\n ('posts',\n  'p2f_AcceptedAnswerId',\n  'posts'): tensor([[     1,     13,     17,  ..., 333881, 333882, 333884],\n         [     0,      9,     16,  ..., 333880, 333832, 333872]])}"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:46:19.817048Z",
     "start_time": "2024-03-14T05:46:19.771957Z"
    }
   },
   "id": "cba42490b6c29fa7",
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "#hetero_data = HeteroData(...)  # A heterogeneous graph data object.\n",
    "model = torch.load(\"C:\\\\Users\\\\Shreya Reddy\\\\Downloads\\\\relbench\\\\examples\\\\saved_model.pth\",\n",
    "                   map_location=torch.device('cpu'))\n",
    "explainer = Explainer(\n",
    "    model,  # It is assumed that model outputs a single tensor.\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config = dict(\n",
    "        mode='binary_classification',\n",
    "        task_level=\"node\",\n",
    "        return_type='probs',  # Model returns probabilities.\n",
    "    ),\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T08:03:08.013389Z",
     "start_time": "2024-03-14T08:03:05.927948Z"
    }
   },
   "id": "2059f95a5c36f633",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:27:58.090484Z",
     "start_time": "2024-03-14T07:27:57.990760Z"
    }
   },
   "id": "4de08abbcebb9bb6",
   "execution_count": 260
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:\n",
      " {'comments': tensor([[ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -3.2116e-01,\n",
      "         -1.0238e-01,  6.1823e-02],\n",
      "        [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.0727e-02,\n",
      "         -3.2732e-03,  5.0768e-02],\n",
      "        [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.7929e-02,\n",
      "          1.2871e-01, -1.6217e-01],\n",
      "        ...,\n",
      "        [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.8093e-01,\n",
      "         -4.8019e-02, -1.4107e-01],\n",
      "        [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.1969e-01,\n",
      "          1.0899e-01, -7.9156e-03],\n",
      "        [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.4080e-01,\n",
      "         -1.0459e-01, -3.6677e-02]]), 'badges': tensor([[   0,    0, 2010,  ...,   19,   39,    7],\n",
      "        [   0,    0, 2010,  ...,   19,   39,    7],\n",
      "        [   0,    0, 2010,  ...,   19,   39,    7],\n",
      "        ...,\n",
      "        [   0,    0, 2020,  ...,   22,   57,   30],\n",
      "        [   0,    0, 2020,  ...,   23,   40,   12],\n",
      "        [   0,    0, 2020,  ...,   23,   55,    3]]), 'postLinks': tensor([[1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.4000e+01, 4.7000e+01,\n",
      "         3.3000e+01],\n",
      "        [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.6000e+01, 3.0000e+01,\n",
      "         4.1000e+01],\n",
      "        [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 9.0000e+00, 1.1000e+01,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 1.9000e+01, 3.1000e+01,\n",
      "         5.9000e+01],\n",
      "        [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.0000e+01,\n",
      "         3.9000e+01],\n",
      "        [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.5000e+01,\n",
      "         2.4000e+01]]), 'postHistory': tensor([[ 1.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -1.4295e-01,\n",
      "         -1.0796e-01,  7.9543e-02],\n",
      "        [ 2.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -2.6364e-01,\n",
      "          7.6387e-02,  7.1052e-02],\n",
      "        [ 3.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -5.2986e-01,\n",
      "          9.9912e-03,  7.9939e-02],\n",
      "        ...,\n",
      "        [ 1.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -1.9610e-01,\n",
      "          2.3302e-01,  1.0279e-01],\n",
      "        [ 3.0000e+00,  1.0000e+00,  2.0200e+03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -3.6696e-02,\n",
      "          1.1555e-01, -2.8800e-02]]), 'votes': tensor([[2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]]), 'users': tensor([[-1.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -4.6642e-02,\n",
      "         -2.3646e-01,  3.8098e-02],\n",
      "        [ 2.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -1.3502e-01,\n",
      "         -4.5602e-02, -2.6330e-02],\n",
      "        [ 3.0000e+00,  2.0100e+03,  6.0000e+00,  ...,  5.9934e-02,\n",
      "         -1.8164e-01, -1.0005e-01],\n",
      "        ...,\n",
      "        [ 1.7282e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01],\n",
      "        [ 2.0342e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01],\n",
      "        [ 4.3574e+06,  2.0200e+03,  1.1000e+01,  ...,  3.3679e-01,\n",
      "          1.9018e-02, -5.6008e-02]]), 'posts': tensor([[ 1.0000e+00,  2.0090e+03,  1.0000e+00,  ..., -1.4295e-01,\n",
      "         -1.0796e-01,  7.9543e-02],\n",
      "        [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01],\n",
      "        [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01],\n",
      "        [ 1.0000e+00,  2.0200e+03,  1.1000e+01,  ..., -1.9610e-01,\n",
      "          2.3302e-01,  1.0279e-01],\n",
      "        [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n",
      "         -2.2297e-01,  3.0119e-01]])}\n",
      "entity_table:n {('comments', 'f2p_UserId', 'users'): tensor([[     2,      5,      9,  ..., 623964, 623965, 623966],\n",
      "        [   957,    884,    957,  ..., 249015, 126602,   1872]]), ('users', 'p2f_UserId', 'comments'): tensor([[     2,      4,      4,  ..., 255334, 255347, 255351],\n",
      "        [ 34710,     43,     57,  ..., 623941, 623944, 623957]]), ('comments', 'f2p_PostId', 'posts'): tensor([[     0,      1,      2,  ..., 623964, 623965, 623966],\n",
      "        [     1,      1,      1,  ..., 333879, 333879, 333437]]), ('posts', 'p2f_PostId', 'comments'): tensor([[     0,      0,      0,  ..., 333881, 333881, 333883],\n",
      "        [413710, 413713, 559727,  ..., 623961, 623962, 623958]]), ('badges', 'f2p_UserId', 'users'): tensor([[     0,      1,      2,  ..., 463460, 463461, 463462],\n",
      "        [     4,      5,      7,  ..., 253733, 255356, 255358]]), ('users', 'p2f_UserId', 'badges'): tensor([[     1,      1,      1,  ..., 255356, 255356, 255358],\n",
      "        [    46,   1505,   3590,  ..., 463457, 463461, 463462]]), ('postLinks', 'f2p_PostId', 'posts'): tensor([[     0,      1,      3,  ...,  77334,  77335,  77336],\n",
      "        [   386,    534,    368,  ...,  65040, 333880, 333872]]), ('posts', 'p2f_PostId', 'postLinks'): tensor([[    26,     28,     28,  ..., 333871, 333872, 333880],\n",
      "        [   515,   1875,  25335,  ...,  77333,  77336,  77335]]), ('postLinks', 'f2p_RelatedPostId', 'posts'): tensor([[     0,      1,      2,  ...,  77334,  77335,  77336],\n",
      "        [   179,    525,    575,  ..., 333498, 233168, 301954]]), ('posts', 'p2f_RelatedPostId', 'postLinks'): tensor([[     9,     23,     23,  ..., 333720, 333772, 333811],\n",
      "        [ 15648,    113,    258,  ...,  77293,  77295,  77323]]), ('postHistory', 'f2p_PostId', 'posts'): tensor([[      0,       1,       2,  ..., 1175365, 1175366, 1175367],\n",
      "        [      0,       0,       0,  ...,  333891,  333891,  333892]]), ('posts', 'p2f_PostId', 'postHistory'): tensor([[      0,       0,       0,  ...,  333891,  333891,  333892],\n",
      "        [      0,       1,       2,  ..., 1175365, 1175366, 1175367]]), ('postHistory', 'f2p_UserId', 'users'): tensor([[      0,       1,       2,  ..., 1175365, 1175366, 1175367],\n",
      "        [  76449,   76449,   76449,  ...,  211410,  211410,  255358]]), ('users', 'p2f_UserId', 'postHistory'): tensor([[      0,       0,       0,  ...,  255354,  255354,  255358],\n",
      "        [     45,      53,      63,  ..., 1175351, 1175352, 1175367]]), ('votes', 'f2p_PostId', 'posts'): tensor([[      0,       1,       2,  ..., 1317873, 1317874, 1317875],\n",
      "        [      2,       6,       6,  ...,  217931,  255319,  232649]]), ('posts', 'p2f_PostId', 'votes'): tensor([[      0,       0,       0,  ...,  333888,  333891,  333892],\n",
      "        [     23,      24,      25,  ..., 1317823, 1317700, 1317759]]), ('votes', 'f2p_UserId', 'users'): tensor([[   1496,    2114,    3004,  ..., 1316844, 1317248, 1317263],\n",
      "        [     50,     166,     166,  ...,    5237,  237981,  141531]]), ('users', 'p2f_UserId', 'votes'): tensor([[      0,       0,       0,  ...,  252504,  252682,  254662],\n",
      "        [  77034,   83838,   85094,  ..., 1310896, 1312798, 1315892]]), ('posts', 'f2p_OwnerUserId', 'users'): tensor([[     0,      1,      3,  ..., 333890, 333891, 333892],\n",
      "        [ 76449,    957,    884,  ..., 216615, 211410, 255358]]), ('users', 'p2f_OwnerUserId', 'posts'): tensor([[     0,      0,      0,  ..., 255341, 255354, 255358],\n",
      "        [  2045,   7837,   8188,  ..., 333869, 333886, 333892]]), ('posts', 'f2p_ParentId', 'posts'): tensor([[     1,      2,      3,  ..., 333889, 333890, 333892],\n",
      "        [     0,      0,      0,  ..., 332888, 320669,  27860]]), ('posts', 'p2f_ParentId', 'posts'): tensor([[     0,      0,      0,  ..., 333873, 333877, 333880],\n",
      "        [     1,      2,      3,  ..., 333875, 333878, 333881]]), ('posts', 'f2p_AcceptedAnswerId', 'posts'): tensor([[     0,      9,     16,  ..., 333873, 333877, 333880],\n",
      "        [     1,     13,     17,  ..., 333875, 333878, 333881]]), ('posts', 'p2f_AcceptedAnswerId', 'posts'): tensor([[     1,     13,     17,  ..., 333881, 333882, 333884],\n",
      "        [     0,      9,     16,  ..., 333880, 333832, 333872]])}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'entity_tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m hetero_explanation \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch_geometric\\explain\\explainer.py:196\u001B[0m, in \u001B[0;36mExplainer.__call__\u001B[1;34m(self, x, edge_index, target, index, **kwargs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    193\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    194\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m should not be provided for the explanation \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplanation_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 196\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_prediction(x, edge_index, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    197\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_target(prediction)\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(index, \u001B[38;5;28mint\u001B[39m):\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch_geometric\\explain\\explainer.py:115\u001B[0m, in \u001B[0;36mExplainer.get_prediction\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 115\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain(training)\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\examples\\model.py:72\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, batch, entity_table)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,batch)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentity_table:n\u001B[39m\u001B[38;5;124m\"\u001B[39m,entity_table)\n\u001B[1;32m---> 72\u001B[0m seed_time \u001B[38;5;241m=\u001B[39m batch[\u001B[43mentity_tables\u001B[49m]\u001B[38;5;241m.\u001B[39mseed_time\n\u001B[0;32m     74\u001B[0m x_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(batch\u001B[38;5;241m.\u001B[39mtf_dict)\n\u001B[0;32m     76\u001B[0m rel_time_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtemporal_encoder(\n\u001B[0;32m     77\u001B[0m     seed_time, batch\u001B[38;5;241m.\u001B[39mtime_dict, batch\u001B[38;5;241m.\u001B[39mbatch_dict\n\u001B[0;32m     78\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'entity_tables' is not defined"
     ]
    }
   ],
   "source": [
    "hetero_explanation = explainer(\n",
    "    feature_dict,\n",
    "    data.edge_index_dict,\n",
    "    index=torch.tensor([2]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T08:03:33.331197Z",
     "start_time": "2024-03-14T08:03:31.987135Z"
    }
   },
   "id": "f95e4e357f9e5a5e",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[259], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Generate batch-wise heterogeneous explanations for\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# the nodes at index `1` and `3`:\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m hetero_explanation \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(hetero_explanation\u001B[38;5;241m.\u001B[39medge_mask_dict)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(hetero_explanation\u001B[38;5;241m.\u001B[39mnode_mask_dict)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch_geometric\\explain\\explainer.py:196\u001B[0m, in \u001B[0;36mExplainer.__call__\u001B[1;34m(self, x, edge_index, target, index, **kwargs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    193\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    194\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m should not be provided for the explanation \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplanation_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 196\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_prediction(x, edge_index, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    197\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_target(prediction)\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(index, \u001B[38;5;28mint\u001B[39m):\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch_geometric\\explain\\explainer.py:115\u001B[0m, in \u001B[0;36mExplainer.get_prediction\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 115\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain(training)\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\examples\\model.py:70\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, batch, entity_table)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     67\u001B[0m     batch: HeteroData,\n\u001B[0;32m     68\u001B[0m     entity_table: NodeType,\n\u001B[0;32m     69\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m---> 70\u001B[0m     seed_time \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[43mentity_table\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mseed_time\n\u001B[0;32m     71\u001B[0m     x_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(batch\u001B[38;5;241m.\u001B[39mtf_dict)\n\u001B[0;32m     73\u001B[0m     rel_time_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtemporal_encoder(\n\u001B[0;32m     74\u001B[0m         seed_time, batch\u001B[38;5;241m.\u001B[39mtime_dict, batch\u001B[38;5;241m.\u001B[39mbatch_dict\n\u001B[0;32m     75\u001B[0m     )\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# Generate batch-wise heterogeneous explanations for\n",
    "# the nodes at index `1` and `3`:\n",
    "hetero_explanation = explainer(\n",
    "    feature_dict,\n",
    "    data.edge_index_dict,\n",
    "    index=torch.tensor([2]),\n",
    ")\n",
    "print(hetero_explanation.edge_mask_dict)\n",
    "print(hetero_explanation.node_mask_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T07:26:01.207291Z",
     "start_time": "2024-03-14T07:26:01.023508Z"
    }
   },
   "id": "f9d253762888662b",
   "execution_count": 259
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'tf': TensorFrame(\n  num_cols=3,\n  num_rows=255360,\n  numerical (1): ['AccountId'],\n  timestamp (1): ['CreationDate'],\n  embedding (1): ['AboutMe'],\n  has_target=False,\n  device='cpu',\n), 'time': tensor([1279522526, 1279548096, 1279553690,  ..., 1609454915, 1609457265,\n        1609457383])}"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_node_store('users')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:59:35.409114Z",
     "start_time": "2024-03-14T05:59:35.399502Z"
    }
   },
   "id": "8aba924ccd93fe57",
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'comments': tensor([[ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -3.2116e-01,\n          -1.0238e-01,  6.1823e-02],\n         [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.0727e-02,\n          -3.2732e-03,  5.0768e-02],\n         [ 2.0090e+03,  1.0000e+00,  1.0000e+00,  ..., -8.7929e-02,\n           1.2871e-01, -1.6217e-01],\n         ...,\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.8093e-01,\n          -4.8019e-02, -1.4107e-01],\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.1969e-01,\n           1.0899e-01, -7.9156e-03],\n         [ 2.0200e+03,  1.1000e+01,  3.0000e+01,  ..., -1.4080e-01,\n          -1.0459e-01, -3.6677e-02]]),\n 'badges': tensor([[   0.,    0., 2010.,  ...,   19.,   39.,    7.],\n         [   0.,    0., 2010.,  ...,   19.,   39.,    7.],\n         [   0.,    0., 2010.,  ...,   19.,   39.,    7.],\n         ...,\n         [   0.,    0., 2020.,  ...,   22.,   57.,   30.],\n         [   0.,    0., 2020.,  ...,   23.,   40.,   12.],\n         [   0.,    0., 2020.,  ...,   23.,   55.,    3.]]),\n 'postLinks': tensor([[1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.4000e+01, 4.7000e+01,\n          3.3000e+01],\n         [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 1.6000e+01, 3.0000e+01,\n          4.1000e+01],\n         [1.0000e+00, 2.0100e+03, 6.0000e+00,  ..., 9.0000e+00, 1.1000e+01,\n          1.0000e+00],\n         ...,\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 1.9000e+01, 3.1000e+01,\n          5.9000e+01],\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.0000e+01,\n          3.9000e+01],\n         [1.0000e+00, 2.0200e+03, 1.1000e+01,  ..., 2.1000e+01, 2.5000e+01,\n          2.4000e+01]]),\n 'postHistory': tensor([[ 1.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -1.4295e-01,\n          -1.0796e-01,  7.9543e-02],\n         [ 2.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -2.6364e-01,\n           7.6387e-02,  7.1052e-02],\n         [ 3.0000e+00,  2.0000e+00,  2.0090e+03,  ..., -5.2986e-01,\n           9.9912e-03,  7.9939e-02],\n         ...,\n         [ 1.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -1.9610e-01,\n           2.3302e-01,  1.0279e-01],\n         [ 3.0000e+00,  1.0000e+00,  2.0200e+03,  ...,  0.0000e+00,\n           0.0000e+00,  0.0000e+00],\n         [ 2.0000e+00,  1.0000e+00,  2.0200e+03,  ..., -3.6696e-02,\n           1.1555e-01, -2.8800e-02]]),\n 'votes': tensor([[2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0090e+03, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         ...,\n         [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [1.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00],\n         [2.0000e+00, 2.0210e+03, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n          0.0000e+00]]),\n 'users': tensor([[-1.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -4.6642e-02,\n          -2.3646e-01,  3.8098e-02],\n         [ 2.0000e+00,  2.0100e+03,  6.0000e+00,  ..., -1.3502e-01,\n          -4.5602e-02, -2.6330e-02],\n         [ 3.0000e+00,  2.0100e+03,  6.0000e+00,  ...,  5.9934e-02,\n          -1.8164e-01, -1.0005e-01],\n         ...,\n         [ 2.0341e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 1.7282e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 2.0342e+07,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01]]),\n 'posts': tensor([[ 1.0000e+00,  2.0090e+03,  1.0000e+00,  ..., -1.4295e-01,\n          -1.0796e-01,  7.9543e-02],\n         [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 2.0000e+00,  2.0090e+03,  1.0000e+00,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         ...,\n         [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01],\n         [ 1.0000e+00,  2.0200e+03,  1.1000e+01,  ..., -1.9610e-01,\n           2.3302e-01,  1.0279e-01],\n         [ 2.0000e+00,  2.0200e+03,  1.1000e+01,  ...,  6.7718e-02,\n          -2.2297e-01,  3.0119e-01]])}"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T06:07:38.825778Z",
     "start_time": "2024-03-14T06:07:38.797975Z"
    }
   },
   "id": "73cf47dc43687034",
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HeteroConv, Linear, SAGEConv\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['users'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:53:15.036649Z",
     "start_time": "2024-03-14T09:53:14.969269Z"
    }
   },
   "id": "d93576e3138cf4ba",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = HeteroGNN(data.metadata(), hidden_channels=64, out_channels=4,\n",
    "                  num_layers=2).to(device)\n",
    "\n",
    "# with torch.no_grad():  # Initialize lazy modules.\n",
    "#     out = model(feature_dict, data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:53:29.841406Z",
     "start_time": "2024-03-14T09:53:29.078129Z"
    }
   },
   "id": "c09f533df963c300",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_nodes = data['users'].num_nodes  # Assuming 'users' is your node type of interest\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "# Example split ratios\n",
    "train_ratio, val_ratio = 0.7, 0.15\n",
    "\n",
    "train_size = int(num_nodes * train_ratio)\n",
    "val_size = int(num_nodes * val_ratio)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size+val_size]] = True\n",
    "test_mask[indices[train_size+val_size:]] = True\n",
    "\n",
    "# Assign masks to HeteroData\n",
    "data['users'].train_mask = train_mask\n",
    "data['users'].val_mask = val_mask\n",
    "data['users'].test_mask = test_mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:40:54.348131Z",
     "start_time": "2024-03-14T10:40:54.337385Z"
    }
   },
   "id": "9573981934aa5498",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('comments',\n  {'tf': TensorFrame(\n    num_cols=2,\n    num_rows=623967,\n    timestamp (1): ['CreationDate'],\n    embedding (1): ['Text'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1233585919, 1233585964, 1233586032,  ..., 1609455955, 1609456624,\n          1609456919])}),\n ('badges',\n  {'tf': TensorFrame(\n    num_cols=3,\n    num_rows=463463,\n    categorical (2): ['Class', 'TagBased'],\n    timestamp (1): ['Date'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1279568347, 1279568347, 1279568347,  ..., 1609455450, 1609458012,\n          1609458903])}),\n ('postLinks',\n  {'tf': TensorFrame(\n    num_cols=2,\n    num_rows=77337,\n    numerical (1): ['LinkTypeId'],\n    timestamp (1): ['CreationDate'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1279723653, 1279902641, 1279962661,  ..., 1609443119, 1609449639,\n          1609449924])}),\n ('postHistory',\n  {'tf': TensorFrame(\n    num_cols=4,\n    num_rows=1175368,\n    numerical (1): ['PostHistoryTypeId'],\n    categorical (1): ['ContentLicense'],\n    timestamp (1): ['CreationDate'],\n    embedding (1): ['Text'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1233584472, 1233584472, 1233584472,  ..., 1609456834, 1609456834,\n          1609458681])}),\n ('votes',\n  {'tf': TensorFrame(\n    num_cols=2,\n    num_rows=1317876,\n    numerical (1): ['VoteTypeId'],\n    timestamp (1): ['CreationDate'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1233532800, 1233532800, 1233532800,  ..., 1609459200, 1609459200,\n          1609459200])}),\n ('users',\n  {'tf': TensorFrame(\n    num_cols=3,\n    num_rows=255360,\n    numerical (1): ['AccountId'],\n    timestamp (1): ['CreationDate'],\n    embedding (1): ['AboutMe'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1279522526, 1279548096, 1279553690,  ..., 1609454915, 1609457265,\n          1609457383])}),\n ('posts',\n  {'tf': TensorFrame(\n    num_cols=5,\n    num_rows=333893,\n    numerical (1): ['PostTypeId'],\n    timestamp (1): ['CreationDate'],\n    embedding (3): ['Body', 'Tags', 'Title'],\n    has_target=False,\n    device='cpu',\n  ), 'time': tensor([1233584472, 1233584671, 1233584698,  ..., 1609456033, 1609456834,\n          1609458681])})]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_items()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:53:53.245465Z",
     "start_time": "2024-03-14T10:53:53.224036Z"
    }
   },
   "id": "e67711e182731ce8",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "255360"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(feature_dict, data.edge_index_dict)  # Ensure 'out' aligns with your model's expected inputs and outputs\n",
    "    mask = data['users'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['users'].y[mask])  # Make sure 'data['users'].y' exists and is properly formatted\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:41:02.015752Z",
     "start_time": "2024-03-14T10:41:02.009201Z"
    }
   },
   "id": "34af89fe8a0cbdc0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(feature_dict, data.edge_index_dict)\n",
    "    mask = data['users'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['users'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask', 'test_mask']:\n",
    "        mask = data['author'][split]\n",
    "        acc = (pred[mask] == data['author'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "          f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:08:48.848062Z",
     "start_time": "2024-03-14T01:08:48.839855Z"
    }
   },
   "id": "4c09c08f4e78d0a2",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Your code that creates and starts processes should go here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# This ensures that multiprocessing is handled correctly\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m \u001B[43mloader_dict\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m      5\u001B[0m         batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, batch)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'loader_dict' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Your code that creates and starts processes should go here\n",
    "    # This ensures that multiprocessing is handled correctly\n",
    "    for batch in loader_dict[\"train\"]:\n",
    "        batch = batch.to(device)\n",
    "        print(\"batch:\\n\", batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:13:31.154434Z",
     "start_time": "2024-03-14T09:13:30.736944Z"
    }
   },
   "id": "cab944ec3baf1d9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:39:00.695188Z",
     "start_time": "2024-03-14T05:39:00.685707Z"
    }
   },
   "id": "22cb834acf36f683",
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:39:04.690612Z",
     "start_time": "2024-03-14T05:39:04.685068Z"
    }
   },
   "id": "75ab246c2fe4bdc6",
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = len(node_feature_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:13:53.332644Z",
     "start_time": "2024-03-14T01:13:53.318668Z"
    }
   },
   "id": "18302836e6ff7932",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[89], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m n:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(tf\u001B[38;5;241m.\u001B[39mfeat_dict(node_feature_name[\u001B[38;5;241m0\u001B[39m]))\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in n:\n",
    "    print(tf.feat_dict(node_feature_name[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:04:30.721784Z",
     "start_time": "2024-03-14T02:04:30.684200Z"
    }
   },
   "id": "4c58c52bf45af860",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Function to combine features from different semantic types\n",
    "def combine_features(tensor_frame, semantic_types):\n",
    "    feature_tensors = []\n",
    "    for stype in semantic_types:\n",
    "        if stype in tensor_frame.feat_dict:\n",
    "            feature_tensors.append(tensor_frame.feat_dict[stype])\n",
    "    if feature_tensors:\n",
    "        return torch.cat(feature_tensors, dim=1)  # Concatenate along the feature axis\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T21:11:26.333200Z",
     "start_time": "2024-03-13T21:11:26.305067Z"
    }
   },
   "id": "9656725f786753db",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Semantic types you want to combine\n",
    "semantic_types = [torch_frame.numerical, torch_frame.categorical]\n",
    "\n",
    "# Iterate over each node type and add combined features to the DGL graph\n",
    "for node_type in data.node_types:\n",
    "    tensor_frame = data[node_type].tf\n",
    "    features = combine_features(tensor_frame, semantic_types)\n",
    "    if features is not None:\n",
    "        dgl_graph.nodes[node_type].data['features'] = features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ea824b31be32125"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgl_graph:\n",
      " Graph(num_nodes={'badges': 463463, 'comments': 623967, 'postHistory': 1175368, 'postLinks': 77337, 'posts': 333893, 'users': 255359, 'votes': 1317876},\n",
      "      num_edges={('badges', 'f2p_UserId', 'users'): 463463, ('comments', 'f2p_PostId', 'posts'): 623962, ('comments', 'f2p_UserId', 'users'): 612288, ('postHistory', 'f2p_PostId', 'posts'): 1175368, ('postHistory', 'f2p_UserId', 'users'): 1100031, ('postLinks', 'f2p_PostId', 'posts'): 61171, ('postLinks', 'f2p_RelatedPostId', 'posts'): 75588, ('posts', 'f2p_AcceptedAnswerId', 'posts'): 57714, ('posts', 'f2p_OwnerUserId', 'users'): 328648, ('posts', 'f2p_ParentId', 'posts'): 167355, ('posts', 'p2f_AcceptedAnswerId', 'posts'): 57714, ('posts', 'p2f_ParentId', 'posts'): 167355, ('posts', 'p2f_PostId', 'comments'): 623962, ('posts', 'p2f_PostId', 'postHistory'): 1175368, ('posts', 'p2f_PostId', 'postLinks'): 61171, ('posts', 'p2f_PostId', 'votes'): 1199831, ('posts', 'p2f_RelatedPostId', 'postLinks'): 75588, ('users', 'p2f_OwnerUserId', 'posts'): 328648, ('users', 'p2f_UserId', 'badges'): 463463, ('users', 'p2f_UserId', 'comments'): 612288, ('users', 'p2f_UserId', 'postHistory'): 1100031, ('users', 'p2f_UserId', 'votes'): 5182, ('votes', 'f2p_PostId', 'posts'): 1199831, ('votes', 'f2p_UserId', 'users'): 5182},\n",
      "      metagraph=[('badges', 'users', 'f2p_UserId'), ('users', 'posts', 'p2f_OwnerUserId'), ('users', 'badges', 'p2f_UserId'), ('users', 'comments', 'p2f_UserId'), ('users', 'postHistory', 'p2f_UserId'), ('users', 'votes', 'p2f_UserId'), ('comments', 'posts', 'f2p_PostId'), ('comments', 'users', 'f2p_UserId'), ('posts', 'posts', 'f2p_AcceptedAnswerId'), ('posts', 'posts', 'f2p_ParentId'), ('posts', 'posts', 'p2f_AcceptedAnswerId'), ('posts', 'posts', 'p2f_ParentId'), ('posts', 'users', 'f2p_OwnerUserId'), ('posts', 'comments', 'p2f_PostId'), ('posts', 'postHistory', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_PostId'), ('posts', 'postLinks', 'p2f_RelatedPostId'), ('posts', 'votes', 'p2f_PostId'), ('postHistory', 'posts', 'f2p_PostId'), ('postHistory', 'users', 'f2p_UserId'), ('postLinks', 'posts', 'f2p_PostId'), ('postLinks', 'posts', 'f2p_RelatedPostId'), ('votes', 'posts', 'f2p_PostId'), ('votes', 'users', 'f2p_UserId')])\n",
      "dgl_graph.nodes['users']:\n",
      " NodeSpace(data={})\n"
     ]
    }
   ],
   "source": [
    "# homogeneous_data = data.to_homogeneous()\n",
    "# print(\"homogeneous_data:\\n\",homogeneous_data)\n",
    "\n",
    "graph_data = {}\n",
    "\n",
    "# For each edge type in the HeteroData\n",
    "for (src_type, edge_type, dst_type), edge_data in data.edge_index_dict.items():\n",
    "    src_nodes, dst_nodes = edge_data\n",
    "    # Convert PyG edge index format to DGL format\n",
    "    graph_data[(src_type, edge_type, dst_type)] = (src_nodes.numpy(), dst_nodes.numpy())\n",
    "\n",
    "# Create the DGL heterograph\n",
    "dgl_graph = dgl.heterograph(graph_data)\n",
    "print(\"dgl_graph:\\n\",dgl_graph)\n",
    "print(\"dgl_graph.nodes['users']:\\n\",dgl_graph.nodes['users'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:36:50.314256Z",
     "start_time": "2024-03-14T02:36:49.651140Z"
    }
   },
   "id": "86017b010dccf813",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:37:19.913116Z",
     "start_time": "2024-03-14T02:37:19.899382Z"
    }
   },
   "id": "568bbb863ac23927",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# model = torch.load(\"C:\\\\Users\\\\Shreya Reddy\\\\Downloads\\\\relbenchmain\\\\examples\\\\saved_model.pth\",\n",
    "#                    map_location=torch.device('cpu'))\n",
    "explainer = HeteroGNNExplainer(model, num_hops=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:37:24.225288Z",
     "start_time": "2024-03-14T02:37:23.945038Z"
    }
   },
   "id": "9654c18b1fef3916",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:39:15.921318Z",
     "start_time": "2024-03-14T02:39:15.911391Z"
    }
   },
   "id": "4f0d59ebd71b4ba6",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[126], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdgl_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\nn\\pytorch\\explain\\gnnexplainer.py:898\u001B[0m, in \u001B[0;36mHeteroGNNExplainer.explain_graph\u001B[1;34m(self, graph, feat, **kwargs)\u001B[0m\n\u001B[0;32m    896\u001B[0m \u001B[38;5;66;03m# Get the initial prediction.\u001B[39;00m\n\u001B[0;32m    897\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 898\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(graph\u001B[38;5;241m=\u001B[39mgraph, feat\u001B[38;5;241m=\u001B[39mfeat, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    899\u001B[0m     pred_label \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    901\u001B[0m feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_masks(graph, feat)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'graph'"
     ]
    }
   ],
   "source": [
    "feat_mask, edge_mask = explainer.explain_graph(dgl_graph, feature_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:37:33.833323Z",
     "start_time": "2024-03-14T02:37:33.472260Z"
    }
   },
   "id": "22486e2b2c70421",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\Shreya Reddy\\.dgl\\ml-100k.zip from https://data.dgl.ai/dataset/ml-100k.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreya Reddy\\.dgl\\ml-100k.zip: 100%|| 9.81M/9.81M [00:00<00:00, 29.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to C:\\Users\\Shreya Reddy\\.dgl\n",
      "Starting processing ml-100k ...\n",
      "End processing ml-100k ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Graph(num_nodes={'movie': 1682, 'user': 943},\n      num_edges={('movie', 'movie-user', 'user'): 100000, ('user', 'user-movie', 'movie'): 100000},\n      metagraph=[('movie', 'user', 'movie-user'), ('user', 'movie', 'user-movie')])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.data import MovieLensDataset\n",
    "dataset = MovieLensDataset(name='ml-100k', valid_ratio=0.2)\n",
    "g = dataset[0]\n",
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T19:41:10.254155Z",
     "start_time": "2024-03-14T19:41:05.424355Z"
    }
   },
   "id": "77f4efc56fa3e2ea",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_mask\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\view.py:80\u001B[0m, in \u001B[0;36mHeteroNodeDataView.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_n_repr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ntid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nodes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\relbenchmain\\venv\\lib\\site-packages\\dgl\\frame.py:688\u001B[0m, in \u001B[0;36mFrame.__getitem__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[0;32m    676\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the column of the given name.\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    686\u001B[0m \u001B[38;5;124;03m        Column data.\u001B[39;00m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 688\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_columns\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mdata\n",
      "\u001B[1;31mKeyError\u001B[0m: 'train_mask'"
     ]
    }
   ],
   "source": [
    "g.nodes[\"user\"].data['train_mask']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T19:45:16.384513Z",
     "start_time": "2024-03-14T19:45:16.152652Z"
    }
   },
   "id": "1e3b46e360e39fa",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_mask = g.edges['user-movie'].data['train_mask']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T19:45:53.376379Z",
     "start_time": "2024-03-14T19:45:53.360508Z"
    }
   },
   "id": "b1c0938c3e08364b",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "998d04d0a4c856f4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.explain import CaptumExplainer, Explainer\n",
    "from torch_geometric.nn import SAGEConv, to_hetero"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T20:28:18.085807Z",
     "start_time": "2024-03-14T20:28:18.066822Z"
    }
   },
   "id": "e1bacbf9a02a3114",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T20:28:30.986034Z",
     "start_time": "2024-03-14T20:28:30.968410Z"
    }
   },
   "id": "6b432ab7ba51a85",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m path \u001B[38;5;241m=\u001B[39m osp\u001B[38;5;241m.\u001B[39mjoin(osp\u001B[38;5;241m.\u001B[39mdirname(osp\u001B[38;5;241m.\u001B[39mrealpath(\u001B[38;5;18;43m__file__\u001B[39;49m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../../data/MovieLens\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m MovieLens(path, model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall-MiniLM-L6-v2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m data \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '../../data/MovieLens')\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T20:28:56.010353Z",
     "start_time": "2024-03-14T20:28:55.978618Z"
    }
   },
   "id": "3fa49d341b262990",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '../../data/MovieLens')\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "data['user', 'movie'].edge_label = data['user',\n",
    "                                        'movie'].edge_label.to(torch.float)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges:\n",
    "data, _, _ = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(\n",
    "        data.x_dict,\n",
    "        data.edge_index_dict,\n",
    "        data['user', 'movie'].edge_label_index,\n",
    "    )\n",
    "    loss = F.mse_loss(pred, data['user', 'movie'].edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='edge',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=200,\n",
    "    ),\n",
    ")\n",
    "\n",
    "index = torch.tensor([2, 10])  # Explain edge labels with index 2 and 10.\n",
    "explanation = explainer(\n",
    "    data.x_dict,\n",
    "    data.edge_index_dict,\n",
    "    index=index,\n",
    "    edge_label_index=data['user', 'movie'].edge_label_index,\n",
    ")\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cd8c1669b2ab19b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7deb0099f20e4af7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8165b632f3267625"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
